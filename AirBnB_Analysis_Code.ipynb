{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_users_2.csv/train_users_2.csv')\n",
    "print(df.shape)\n",
    "df['date_account_created'] = df.date_account_created.apply(lambda x : datetime.strptime(x,'%d-%m-%Y'))\n",
    "df['date_first_booking'] = pd.to_datetime(df['date_first_booking'],errors = 'coerce')\n",
    "df.sort_values('date_account_created', inplace = True)\n",
    "df = df.reset_index()\n",
    "del df['index']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['days_since_first_day'] = [ date - df.loc[0,'date_account_created'] for date in df['date_account_created']]\n",
    "df['days_since_first_day'] = df['days_since_first_day'].dt.days\n",
    "df['Day'] = df.date_account_created.apply(lambda x : x.day)\n",
    "df['Month'] = df.date_account_created.apply(lambda x :x.month)\n",
    "df['Year'] = df.date_account_created.apply(lambda x :x.year)\n",
    "df['Quarter'] =df.date_account_created.apply(lambda x :np.ceil(x.month/3))\n",
    "df['Week_Year'] = df.date_account_created.apply(lambda x :np.ceil((x.isocalendar()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['timestamp_first_active'] = df['timestamp_first_active'].astype(str)\n",
    "df['timestamp_first_active']  = df.timestamp_first_active.apply(lambda x: datetime.strptime(x,'%Y%m%d%H%M%S'))\n",
    "df['firstactivediff'] = (df['timestamp_first_active'] - df['date_account_created']).dt.days\n",
    "df['firstactivediff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis, Missing and Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID vs Date\n",
    "cnt_users = df.groupby('date_account_created')['id'].size()\n",
    "plt.scatter(cnt_users.index,cnt_users)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Booking\n",
    "print(df.date_first_booking.isnull().sum()/df.shape[0]*100)\n",
    "diff = df['date_first_booking'] - df['date_account_created']\n",
    "print(diff.describe())\n",
    "#diff[diff.notnull()]\n",
    "sum(diff[diff.notnull()]<'0 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distribution of other Categorical columns\n",
    "print(df.groupby('signup_method').size())\n",
    "print(df.groupby('language').size())\n",
    "print(df.groupby('affiliate_channel').size())\n",
    "print(df.groupby('affiliate_provider').size())\n",
    "print(df.groupby('first_affiliate_tracked').size())\n",
    "print(df.groupby('signup_app').size())\n",
    "print(df.groupby('first_device_type').size())\n",
    "print(df.groupby('first_browser').size())\n",
    "print(df.groupby('country_destination').size()/len(df)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Signup Flow\n",
    "plt.hist(df.signup_flow)\n",
    "plt.xlabel('SignUp Flow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "df['gender'] = [g.replace('-unknown-','None') for g in df['gender']]\n",
    "print((len([g for g in df['gender'] if g == 'None'])/df.shape[0])* 100)\n",
    "print(df.groupby('gender')['id'].size()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imputing Missing Values in Gender\n",
    "\n",
    "# Converting categorical to dummy variables\n",
    "categorical = df.iloc[:,np.r_[4,6,8:16]]\n",
    "dummy_categorical = pd.get_dummies(categorical)\n",
    "df_num_dum = pd.concat([df.iloc[:,np.r_[0:4,5,7,16:len(df.columns)]],dummy_categorical],axis=1)\n",
    "df_all = pd.concat([df_num_dum,df.iloc[:,np.r_[4,6,8:16]]],axis=1)\n",
    "\n",
    "\n",
    "test = df_num_dum[df_num_dum['gender_None']==1]\n",
    "train = df_num_dum[df_num_dum['gender_None']!=1]\n",
    "X_train = train[train.columns.difference(['gender_OTHER','id','gender_None','gender_FEMALE','gender_MALE','age','date_account_created','timestamp_first_active','date_first_booking'])]\n",
    "X_test = test[test.columns.difference(['id','gender_None','gender_OTHER','gender_FEMALE','gender_MALE','age','date_account_created','timestamp_first_active','date_first_booking'])] \n",
    "Y_train = df_all.loc[df_all['gender_None']!=1,'gender']\n",
    "Y_test = df_all.loc[df_all['gender_None']==1,'gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing multicollinear variables\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns\n",
    "noinf = list(vif[~np.isinf(vif['VIF Factor'])].features)\n",
    "vif2 = pd.DataFrame()\n",
    "filt_Xtrain = X_train[noinf]\n",
    "vif2[\"VIF Factor\"] = [variance_inflation_factor(filt_Xtrain.values, i) for i in range(filt_Xtrain.shape[1])]\n",
    "vif2[\"features\"] = filt_Xtrain.columns\n",
    "viffilt = list(vif2[vif2['VIF Factor'] < 50].features)\n",
    "filt2_Xtrain = filt_Xtrain[viffilt]\n",
    "vif3 = pd.DataFrame()\n",
    "vif3[\"VIF Factor\"] = [variance_inflation_factor(filt2_Xtrain.values, i) for i in range(filt2_Xtrain.shape[1])]\n",
    "vif3[\"features\"] = filt2_Xtrain.columns\n",
    "filt = list(vif3[vif3['VIF Factor'] < 6].features)\n",
    "filt3_Xtrain = filt_Xtrain[filt]\n",
    "\n",
    "\n",
    "# Linear Discriminant Analysis to predict Gender\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(filt3_Xtrain,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction and checking\n",
    "pred = clf.predict(X_test[filt])\n",
    "pred_gender = pd.DataFrame({'gender_pred': pred},index = Y_test.index)\n",
    "print(pred_gender.groupby('gender_pred').size()/pred_gender.shape[0])\n",
    "\n",
    "#Imputing Gender with predicted values\n",
    "df.loc[df.gender == 'None','gender'] = list(pred)\n",
    "print(df.groupby('gender').size()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "#Checking percentile\n",
    "print(np.nanpercentile(df.age,[0,1,5,10,50,90,95,99]))\n",
    "print(len(df.loc[df.age<6,'age']))\n",
    "# Removing rows with age < 6 \n",
    "df = df[(df.age > 5) | np.isnan(df.age) ]\n",
    "print(df.shape)\n",
    "\n",
    "# Imputing age with values >105 to 105\n",
    "df.loc[df.age > 105.0,'age'] = 105.0\n",
    "\n",
    "#Imputing Missing values with median\n",
    "print(df.age.isnull().sum()/df.shape[0]* 100)\n",
    "df.loc[df.age.isnull(),'age'] = df.age.median()\n",
    "\n",
    "plt.hist(df.age)\n",
    "plt.xlabel('Age after imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.date_account_created < '2014-02-01 00:00:00','Split'] = \"Train\"\n",
    "df.loc[df.date_account_created >= '2014-02-01 00:00:00','Split'] = \"Test\"\n",
    "df.groupby('Split').size()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing multicollinear variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = df.iloc[:,np.r_[4,6,8:15]]\n",
    "dummy_categorical = pd.get_dummies(categorical)\n",
    "inp = pd.concat([df.iloc[:,np.r_[22,15,5,7]],dummy_categorical,],axis=1)\n",
    "inp = inp[inp.columns.difference(['gender_OTHER','signup_method_basic','language_zh','affiliate_channel_other','affiliate_provider_other','first_affiliate_tracked_untracked','signup_app_iOS','first_device_type_Other/Unknown','first_browser_-unknown-',])]\n",
    "temp = inp[inp.columns.difference(['Split','country_destination'])]\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(temp.values, i) for i in range(temp.shape[1])]\n",
    "vif[\"features\"] = temp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "upsample = pd.DataFrame()\n",
    "dest = inp['country_destination'].unique()\n",
    "for i in dest:\n",
    "    if i in [\"NDF\",\"US\",\"other\"]:\n",
    "        t = resample(inp[inp['country_destination'] == i],replace = False,n_samples =10000,random_state = 1234)\n",
    "        upsample = upsample.append(t,ignore_index=True)\n",
    "    else:\n",
    "        t = resample(inp[inp['country_destination'] == i],n_samples = 10000,random_state = 1234)\n",
    "        upsample = upsample.append(t,ignore_index=True)\n",
    "print(upsample.shape)\n",
    "\n",
    "\n",
    "trn_X = upsample.loc[upsample.Split == 'Train',vif[vif['VIF Factor']<5].features]\n",
    "test_X = upsample.loc[upsample.Split == 'Test',vif[vif['VIF Factor']<5].features]\n",
    "trn_Y = upsample.loc[upsample.Split == 'Train','country_destination']\n",
    "test_Y = upsample.loc[upsample.Split == 'Test','country_destination']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG - Evaluation Metric Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "def ndcg(ground_truth, predictions, k=5):\n",
    "    t = pd.DataFrame({'test':test_Y})\n",
    "    T = (pd.get_dummies(t)).as_matrix()\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr_resample = linear_model.LogisticRegression(multi_class = 'multinomial',solver ='lbfgs',max_iter = 100)\n",
    "result_lr_resample = model_lr_resample.fit(trn_X,trn_Y)\n",
    "pred_lr_resample = model_lr_resample.predict_proba(test_X)\n",
    "metrics.accuracy_score(test_Y,pred_lr_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using LBFGS Solver\n",
    "model_lr_resample = linear_model.LogisticRegression(multi_class = 'multinomial',solver ='lbfgs',max_iter = 100)\n",
    "result_lr_resample = model_lr_resample.fit(trn_X,trn_Y)\n",
    "pred_lr_resample = model_lr_resample.predict_proba(test_X)\n",
    "ndcg(test_Y_tr,pred_lr_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 2-Fold CV\n",
    "cv = inp[inp.columns.difference(['Split','country_destination'])]\n",
    "target = inp['country_destination']\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=2) # Define the split - into 10 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_lr_prob = model_lr_resample.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_lr_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 5-Fold CV\n",
    "cv = inp[inp.columns.difference(['Split','country_destination'])]\n",
    "target = inp['country_destination']\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=5) # Define the split - into 10 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_lr_prob = model_lr_resample.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_lr_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 5-Fold CV\n",
    "cv = inp[inp.columns.difference(['Split','country_destination'])]\n",
    "target = inp['country_destination']\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 10 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_lr_prob = model_lr_resample.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_lr_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(eta = 0.2,base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
    "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1,eval_metric = 'ndcg@5')\n",
    "model_xgb.fit(trn_X, trn_Y)\n",
    "pred_xgb = model_xgb.predict_proba(test_X)\n",
    "ndcg(test_Y,pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 2-Fold CV\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=2) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_xgb_prob = model_xgb.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_xgb_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 5-Fold CV\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_xgb_prob = model_xgb.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_xgb_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NDCG Score for 10-Fold CV\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_xgb_prob = model_xgb.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_xgb_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(trn_X, trn_Y)\n",
    "\n",
    "pred_rf = model_rf.predict(test_X)\n",
    "pred_rf_prob = model_rf.predict_proba(test_X)\n",
    "\n",
    "print(collections.Counter(pred_rf))\n",
    "\n",
    "ndcg(test_Y,pred_rf_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-Fold CV - max depth=4\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    model_rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=4)\n",
    "    pred_cv_rf_prob = model_rf.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_rf_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-Fold CV - max depth=3\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    model_rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=3)\n",
    "    pred_cv_rf_prob = model_rf.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_rf_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-Fold CV - max depth=2\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    model_rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=2)\n",
    "    pred_cv_rf_prob = model_rf.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_rf_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-Fold CV - max depth=1\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    model_rf = RandomForestClassifier(n_estimators=600,criterion='gini', max_depth=4)\n",
    "    pred_cv_rf_prob = model_rf.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_rf_prob))\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlNB = MultinomialNB()\n",
    "mlNB.fit(trn_X,trn_Y)\n",
    "pred_NB = mlNB.predict_proba(test_X)\n",
    "ndcg(test_Y,pred_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10-fold CV \n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits=10) # Define the split - into 5 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "mlNB = MultinomialNB()\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    pred_cv_NB_prob = mlNB.fit(X_train,y_train).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_NB_prob))\n",
    "#print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold CV with 1 layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=96, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10) # Define the split - into 5 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    train_Y_cat = pd.get_dummies(y_train)\n",
    "    pred_cv_nn_prob = model.fit(X_train,train_Y_cat,epochs=50, batch_size=10).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_nn_prob))\n",
    "#print(res)\n",
    "print(np.mean(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold CV with 2 layers - 10,10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=96, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10) # Define the split - into 5 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    train_Y_cat = pd.get_dummies(y_train)\n",
    "    pred_cv_nn_prob = model.fit(X_train,train_Y_cat,epochs=50, batch_size=10).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_nn_prob))\n",
    "#print(res)\n",
    "print(np.mean(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold CV with 2 layers - 10,8 nodes \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=96, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10) # Define the split - into 5 folds \n",
    "kf.get_n_splits(cv) # returns the number of splitting iterations in the cross-validator\n",
    "res=[]\n",
    "for train_index, test_index in kf.split(cv):\n",
    "    X_train, X_test = cv[cv.index.isin(train_index)], cv[cv.index.isin(test_index)]\n",
    "    y_train, y_test = target[cv.index.isin(train_index)], target[cv.index.isin(test_index)]\n",
    "    train_Y_cat = pd.get_dummies(y_train)\n",
    "    pred_cv_nn_prob = model.fit(X_train,train_Y_cat,epochs=50, batch_size=10).predict_proba(X_test)\n",
    "    test_Y_tr = le.transform(y_test)\n",
    "    res.append(ndcg(test_Y_tr,pred_cv_nn_prob))\n",
    "#print(res)\n",
    "print(np.mean(res))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
